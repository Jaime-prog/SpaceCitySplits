Segmentaci√≥n de Im√°genes Urbanas
---
Este README proporciona una descripci√≥n detallada del proyecto de segmentaci√≥n sem√°ntica de im√°genes. El proyecto se basa en el uso de un conjunto de datos de segmentaci√≥n sem√°ntica de im√°genes urbanas llamado "Cityscapes Image Pairs".

- El conjunto de datos se puede consultar a trav√©s de la plataforma de kaggle en la siguiente liga: [_Cityscapes Image Pairs Dataset_](https://www.kaggle.com/datasets/dansbecker/cityscapes-image-pairs/data).
- El jupyternotebook se encuentra en la siguiente liga: [_Image_Segmentation.ipynb_](https://colab.research.google.com/drive/1Pfqk_PoN-YN1KyA3a5ZTAgudswapfH6P?usp=sharing)
- Se ha creado un proyecto de Google Colab adem√°s de las carpetas necesarias en la siguiente [_Ubicaci√≥n_](https://drive.google.com/drive/folders/1m7DZ6JIDJk5MSV1IQJvLZ2E4pBZJO__X?usp=sharing)


## :arrow_right: Contenido del repositorio 

 _Archivos/Scripts_: 
- `Image_Segmentation_City.ipynb` 

## Dataset :information_source:

**Nombre del dataset**: Cityscapes Image Pairs

**Variables**: Las im√°genes del conjunto de datos tienen un formato de 256x512 p√≠xeles y 3 canales (RGB). El conjunto de datos est√° dividido en directorios de entrenamiento y validaci√≥n. Este conjunto de datos comprende im√°genes urbanas con etiquetas de segmentaci√≥n sem√°ntica.

Inicialmente esta es la distribuci√≥n de las carpetas:

- _Train_: **2975** im√°genes de entrenamiento
- Test: **500** im√°genes de validaci√≥n

Las im√°genes muestran la segmentaci√≥n sem√°ntica junto con la imagen original, lo que lo convierte en un conjunto de datos valioso para tareas de segmentaci√≥n sem√°ntica en entornos urbanos.

## Objetivo :dart:
El objetivo principal de este proyecto es desarrollar segmentaci√≥n sem√°ntica de im√°genes urbanas. La cual tiene aplicaciones en la identificaci√≥n y delimitaci√≥n de objetos en entornos urbanos, lo que es fundamental para diversas aplicaciones como la conducci√≥n aut√≥noma, la planificaci√≥n urbana y la vigilancia.

Desarrollar un modelo preciso de segmentaci√≥n sem√°ntica de im√°genes urbanas mediante deep learning representa una contribuci√≥n significativa para la investigaci√≥n en visi√≥n por computadora y sus aplicaciones pr√°cticas en entornos urbanos.

## :bookmark_tabs: Justificaci√≥n y respaldo en la literatura
Para la resoluci√≥n de este problema, en cu√°nto a la metodolog√≠a y a la utilizaci√≥n de ciertas funciones se basaron en los resultados del siguiente paper 
[Deep Semantic Segmentation of Angiogenesis Images
](https://www.mdpi.com/1422-0067/24/2/1102)

## :gear: Preprocesamiento de datos

- **Redimensionamiento**: Im√°genes y m√°scaras se ajustaron a 192x192 p√≠xeles para coherencia espacial.
- **Conversi√≥n de color:** Se cambi√≥ de BGR a RGB para compatibilidad con modelos de aprendizaje profundo.
- **Normalizaci√≥n:** Valores de p√≠xeles se escalaron a un rango de 0 a 1 para estabilidad.
- **Partici√≥n:** Im√°genes se dividieron en entrada y m√°scara para entrenamiento adecuado.
- **Divisi√≥n de datos:** 2,900 muestras para entrenamiento y el resto para validaci√≥n.

## :diamond_shape_with_a_dot_inside: Arquitectura del modelo
  Para este problema se decidio implementar un unet autoencoder para poder hacer la segmentaci√≥n de im√°genes. Para esta arquitectura contamos con 2 partes esenciales: 
  - EncoderLayerBlock
 
Esta secci√≥n de la arquitectura es la que se encarga de poder captar las caracter√≠sticas tanto de nivel bajo como de nivel alto. Algunos ejemplos de estas caracter√≠sticas de bajo nivel podr√≠an incluir, los colores, las figuras b√°sicas, los bordes, etc. Mientras que las caracter√≠sticas de alto nivel tienen que ver con patrones m√°s intr√≠nsecos dentro de la imagen. Ahora bien, en esta arquitectura en especifica se cuenta con la secci√≥n de las **capas de convoluci√≥n** que son las encargadas de extraer las caracter√≠sticas antes mencionadas, y capas de max pooling que son las encargadas de reducir el espacio dimensional de la im√°gen. En este caso se configuro 2 capas de convoluci√≥n en un kernel de 3x3 y tras esta operaci√≥n se realiza el max pooling.
  - DecoderLayerBlock

Esta secci√≥n se encarga de generar la segmentaci√≥n final, lo cual hace a partir de sobremuestrar 'upsampling' para poder incrementar las dimensiones espaciales del mapa de caracter√≠sticas. En este caso el tama√±o del kernel es de (2,2) y el stride se configuro en (2,2) lo que resulta en aumentar en un factor de 2 espacio dimensional. El upsampling se configura con una capa de 'Conv2DTranspose' que tambi√©n se conoce como deconvolution lo cual nos ayuda a reconstruir una imagen a partir de una versi√≥n comprimida (en este caso proveniente del encoder). 

Despu√©s configuramos como tal la arquitectura del unet autoencoder, en el cual se configura 4 bloques del Encoder y despu√©s se tiene una capa que procesa la versi√≥n m√°s comprimida de la imagen con el mayor n√∫mero de filtros y despu√©s se configuran otros 4 bloques de Decoder el cual progresivamente va aumentando el espacio dimensional. Y para la capa de la salida se busca generar o reconstruir la imagen de entrada entonces se utiliza la funci√≥n 'sigmoid' para delimitar el output de 0 a 1 para cada uno de los pixeles normalizados. Adicionalmente, se define el 'padding:same' porque se quiere la imagen reconstruida tenga las mismas dimensiones que la imagen original o la imagen de entrada. 

## Resultados y Evaluaci√≥n Inicial :chart:

El modelo de segmentaci√≥n sem√°ntica fue entrenado y evaluado en el conjunto de datos "Cityscapes Image Pairs". A continuaci√≥n, presentamos los resultados obtenidos:

- **(Test Loss):** Un valor de 0.5688 indica que el modelo a√∫n tiene margen para mejorar en la predicci√≥n precisa de las etiquetas de las im√°genes. 
- **(Test Accuracy):** Una precisi√≥n de 0.7107 sugiere que el modelo acierta en la clasificaci√≥n de aproximadamente el 71% de las im√°genes.
- **IoU (Mean Intersection over Union):** Un IoU promedio de 0.9297 indica que el modelo predice con alta precisi√≥n la superposici√≥n entre las √°reas segmentadas y las √°reas reales. Un IoU cercano a 1 indica una coincidencia casi perfecta entre las segmentaciones predichas y reales.
- **Coeficiente de Dice:** Para esta m√©trica se obtuvo un coeficiente de Dice de 0.4273. El coeficiente de Dice se enfoca en la evaluaci√≥n de la coincidencia de volumen entre las segmentaciones, y un valor cercano a 1 indica una alta coincidencia de volumen.

## Resultados y Evaluaci√≥n al mejorar el modelo :writing_hand:
- Intersecci√≥n media sobre la Uni√≥n (IoU): 0.9297
La m√©trica de intersecci√≥n media sobre la uni√≥n (IoU) mide la superposici√≥n entre las m√°scaras de segmentaci√≥n previstas y las m√°scaras reales. Una puntuaci√≥n IoU de 0.9297 indica un alto nivel de concordancia entre las m√°scaras de segmentaci√≥n predichas y las reales, con una parte significativa de la m√°scara predicha que se solapa con la m√°scara real.

- Coeficiente Dice: 0.4587
El coeficiente Dice es otra m√©trica utilizada habitualmente para evaluar la similitud entre dos conjuntos. Un coeficiente Dice de 0.4587 indica que alrededor del 45.87% de los p√≠xeles de la m√°scara predicha coinciden con los p√≠xeles de la m√°scara real. Aunque este valor es inferior en comparaci√≥n con el IoU, sigue indicando un nivel moderado de concordancia entre las m√°scaras predicha y real.

## Principales Cambios con Respecto al Modelo Base üìè
- **Optimizador:** He utilizado el optimizador Adam con una tasa de aprendizaje de 0.001. Esto ayuda a mejorar el rendimiento del modelo mediante la adaptaci√≥n din√°mica del aprendizaje.
- **N√∫mero de √©pocas:** He aumentado el n√∫mero de √©pocas a 90, lo que permite que el modelo se entrene durante un per√≠odo m√°s largo y consiga potencialmente un mejor rendimiento.
- **T√©cnicas de regularizaci√≥n:** He utilizado dropout para introducir aleatoriedad durante el entrenamiento y evitar el sobreajuste. Esta t√©cnica evita que el modelo memorice los datos de entrenamiento y generalice mal a nuevos datos.
- **Inicializador del n√∫cleo:** He utilizado el inicializador de kernel 'he_normal' para inicializar los pesos de las capas convolucionales. Esto ayuda a evitar que el modelo se sobreajuste

_En este caso el enfoque de las mejoras se quisieron hacer a partir de mejorar otros aspectos fuera de solo utilizar transfer learning, entonces se enfoco en hiperparametros y otras caracter√≠sticas_

## Uso Im√°genes Reales :triangular_flag_on_post:
![Screenshot output base model](https://github.com/Jaime-prog/SpaceCitySplits/blob/main/Resoure_Images/output_base_model.png)

![Screenshot output improved model](https://github.com/Jaime-prog/SpaceCitySplits/blob/main/Resoure_Images/output_improved_model.png)

![Screenshot output improved model](https://github.com/Jaime-prog/SpaceCitySplits/blob/main/Resoure_Images/latest_result.png)


 _Los resultados finales se encuentran documentados en el reporte_

## :small_blue_diamond: Uso

Para utilizar estos scripts, siga estos pasos generales:

1. Clona este repositorio en tu entorno local:

   ```bash
   git clone https://github.com/Jaime-prog/SpaceCitySplits.git
   ```
2. Modifique los scripts seg√∫n sea necesario para adaptarlos a su equipo espec√≠fico. Por ejemplo, la ubicaci√≥n de los archivos.
3. Ejecute los scripts deseados desde la l√≠nea de comandos, utilizando Python para los scripts Python y bash para el script shell.
  
   ```
    EvaluateModel.ipynb
   ```

---
# Referencias
- Ibragimov, A., Sofya Senotrusova, Kseniia Markova, Evgeny Karpulevich, Ivanov, A., Elizaveta Tyshchuk, Polina Grebenkina, Stepanova, O., Sirotskaya, A., Anastasiia Kovaleva, Arina Oshkolova, Zementova, M., Viktoriya Konstantinova, Kogan, I., Sergey Selkov, & Sokolov, D. (2023). Deep Semantic Segmentation of Angiogenesis Images. International Journal of Molecular Sciences, 24(2), 1102‚Äì1102. https://doi.org/10.3390/ijms24021102
- prvnkmr. (2021, January 11). UNet Architecture Breakdown. Kaggle.com; Kaggle. https://www.kaggle.com/code/prvnkmr/unet-architecture-breakdown

‚Äå

‚Äå
